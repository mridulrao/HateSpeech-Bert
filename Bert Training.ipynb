{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f299b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kawaii/opt/miniconda3/envs/hate_speech/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AdamW,BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be3e1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba416cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>label</th>\n",
       "      <th>extra_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33395</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>JEW Get the fuck out of here you jewish son of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28713</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>GET RID OF THOSE FUCKING MUSLIMS! the nasty on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25664</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>@Balwant58644969 @gushi22 @Insaniat_parast @ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28811</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>There are not any jew signatures on our Declar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24408</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Put them in a airplane, and take them back to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34234</th>\n",
       "      <td>14377</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>These regional ministers...this is why our chu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34235</th>\n",
       "      <td>8035</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>HAPPY BIRTHDAY jaden,enjoy life being gay and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34236</th>\n",
       "      <td>33918</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>@BeyLegion This exactly why bey did this song....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34237</th>\n",
       "      <td>21084</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>If I were you, I'd reclaim her body again. Sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34238</th>\n",
       "      <td>29408</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>gay people should die</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34239 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id  label extra_label  \\\n",
       "0          33395      1           a   \n",
       "1          28713      1           a   \n",
       "2          25664      0           a   \n",
       "3          28811      1           a   \n",
       "4          24408      1           a   \n",
       "...          ...    ...         ...   \n",
       "34234      14377      0           a   \n",
       "34235       8035      0           a   \n",
       "34236      33918      0           a   \n",
       "34237      21084      1           a   \n",
       "34238      29408      1           a   \n",
       "\n",
       "                                                    text  \n",
       "0      JEW Get the fuck out of here you jewish son of...  \n",
       "1      GET RID OF THOSE FUCKING MUSLIMS! the nasty on...  \n",
       "2      @Balwant58644969 @gushi22 @Insaniat_parast @ma...  \n",
       "3      There are not any jew signatures on our Declar...  \n",
       "4      Put them in a airplane, and take them back to ...  \n",
       "...                                                  ...  \n",
       "34234  These regional ministers...this is why our chu...  \n",
       "34235  HAPPY BIRTHDAY jaden,enjoy life being gay and ...  \n",
       "34236  @BeyLegion This exactly why bey did this song....  \n",
       "34237  If I were you, I'd reclaim her body again. Sho...  \n",
       "34238                              gay people should die  \n",
       "\n",
       "[34239 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.tsv', delimiter='\\t', header=None, names=['unique_id', 'label', 'extra_label', 'text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c66ed500",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.text.values\n",
    "\n",
    "# Adding CLS and SEP tokens at the beginning and end of each sentence for BERT\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505fad77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'jew', 'get', 'the', 'fuck', 'out', 'of', 'here', 'you', 'jewish', 'son', 'of', 'a', 'bitch', ',', 'i', \"'\", 'll', 'rape', 'your', 'fucking', 'family', 'if', 'you', 'don', \"'\", 't', 'leave', 'you', 'semi', '##te', 'bastard', '.', 'i', 'will', 'shoot', 'you', 'if', 'you', 'return', ',', 'because', 'you', \"'\", 're', 'a', 'dirty', 'semi', '##te', ',', 'i', 'hope', 'you', 'choke', 'on', 'a', 'fucking', 'bag', '##el', ',', 'prick', '.', 'sha', '##lom', '.', 'we', 'came', 'in', '?', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f2cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "# Use the BERT Tokenizer to convert the tokens to their index numbers in the BERT vocalubary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# Pad our input tokens to max length\n",
    "input_ids = pad_sequences(input_ids,maxlen=MAX_LEN,dtype=\"long\",truncating=\"post\",padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a09ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5367f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, \n",
    "                                                                                    labels, \n",
    "                                                                                    random_state=2018, \n",
    "                                                                                    test_size=0.1)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input_ids,\n",
    "                                                        random_state=2018, \n",
    "                                                       test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e07bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torch tensors are the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf28b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be20a31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "from transformers import BertModel, BertConfig\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48698618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f702a4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.34.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6aac3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't apply weight decay to any parameters whose names include these tokens.\n",
    "# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n",
    "param_optimizer = list(model.named_parameters())\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "# Separate the `weight` parameters from the `bias` parameters. \n",
    "# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01. \n",
    "# - For the `bias` parameters, the 'weight_decay_rate' is 0.0. \n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.1},\n",
    "    \n",
    "    # Filter for parameters which *do* include those.\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0a3128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kawaii/opt/miniconda3/envs/hate_speech/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                  )\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "# `train_dataloader` contains batched data so `len(train_dataloader)` gives \n",
    "# us the number of batches.\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fd464a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d8fab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Training Loop\n",
    "t = [] \n",
    "\n",
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9b9a758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|                                                                                                                                   | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.054611350566538985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|█████████████████████████████▎                                                                                       | 1/4 [1:33:00<4:39:02, 5580.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9883177570093458\n",
      "Train loss: 0.009348601092961482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|██████████████████████████████████████████████████████████▌                                                          | 2/4 [3:03:14<3:02:44, 5482.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9894859813084113\n",
      "Train loss: 0.0021725765699531587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|███████████████████████████████████████████████████████████████████████████████████████▊                             | 3/4 [4:33:13<1:30:44, 5444.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.991822429906542\n",
      "Train loss: 0.00037843999737051755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [6:04:08<00:00, 5462.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.991822429906542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "    # Set our model to training mode (as opposed to evaluation mode)\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    # Train the data for one epoch\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs['loss']\n",
    "        train_loss_set.append(loss.item())    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    # Validation\n",
    "\n",
    "    # Put model in evaluation mode to evaluate loss on the validation set\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    \n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits['logits'].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "        \n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14fa13cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>JEW Get the fuck out of here you jewish son of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This is how I too feel about #LGBTQ #Pride It'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>You're right, I didn't think about that. And w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I am transgender but I'm also mentally ill but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>trump is the only jews true friend. I hope tru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8642</th>\n",
       "      <td>8642</td>\n",
       "      <td>Hitler didn't finish it. Can u. If a nigger ur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8643</th>\n",
       "      <td>8643</td>\n",
       "      <td>Ah yeah, I'm actually Dominican myself! And mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8644</th>\n",
       "      <td>8644</td>\n",
       "      <td>\"@iamkrause: No need to thank me, killing nigg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8645</th>\n",
       "      <td>8645</td>\n",
       "      <td>+Kinda Linda yea I know I just wish people wou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8646</th>\n",
       "      <td>8646</td>\n",
       "      <td>Hey ,muslim dickhead !!!!!!!! Why don;t you go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id                                               text  label\n",
       "0             0  JEW Get the fuck out of here you jewish son of...      1\n",
       "1             1  This is how I too feel about #LGBTQ #Pride It'...      0\n",
       "2             2  You're right, I didn't think about that. And w...      0\n",
       "3             3  I am transgender but I'm also mentally ill but...      0\n",
       "4             4  trump is the only jews true friend. I hope tru...      1\n",
       "...         ...                                                ...    ...\n",
       "8642       8642  Hitler didn't finish it. Can u. If a nigger ur...      1\n",
       "8643       8643  Ah yeah, I'm actually Dominican myself! And mu...      0\n",
       "8644       8644  \"@iamkrause: No need to thank me, killing nigg...      1\n",
       "8645       8645  +Kinda Linda yea I know I just wish people wou...      0\n",
       "8646       8646  Hey ,muslim dickhead !!!!!!!! Why don;t you go...      1\n",
       "\n",
       "[8647 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test_labels.tsv', delimiter='\\t', header=None, \n",
    "                      names=['unique_id', 'text', 'label'])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a96e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.text.values\n",
    "\n",
    "# Adding special tokens at the start and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = df.label.values\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24cf5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de83b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "  \n",
    "batch_size = 32  \n",
    "\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e73f3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to CPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits['logits'].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8af543de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_set = []\n",
    "\n",
    "for i in range(len(true_labels)):\n",
    "    matthews = matthews_corrcoef(true_labels[i],\n",
    "                 np.argmax(predictions[i], axis=1).flatten())\n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d7a0e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9983003660816576"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "# print(flat_predictions)\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "print(min(flat_predictions))\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "# print(flat_true_labels)\n",
    "matthews_corrcoef(flat_true_labels, flat_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54f4c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'This bitch needs to be silent'\n",
    "\n",
    "sentence = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "tokenized_sentence = [tokenizer.tokenize(sentence)]\n",
    "\n",
    "MAX_LEN = 128\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_sentence]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c29e44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 101 2023 7743 3791 2000 2022 4333  102    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9dfae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f8cc2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6e2eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "logits = model(prediction_inputs, token_type_ids=None, attention_mask=prediction_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9510992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.7897,  4.3276]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71cd0832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7897427,  4.3276453]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits['logits'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa039b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c8f170c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'She loves to cook'\n",
    "\n",
    "sentence = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "tokenized_sentence = [tokenizer.tokenize(sentence)]\n",
    "\n",
    "MAX_LEN = 128\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_sentence]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c1b741dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.303495, -4.609913]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "\n",
    "model.eval()\n",
    "logits = model(prediction_inputs, token_type_ids=None, attention_mask=prediction_masks)\n",
    "\n",
    "logits['logits'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "efba6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "predictions.append(logits['logits'].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2f553961",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_predictions = [item for sublist in predictions for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a7d800aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 4.303495, -4.609913], dtype=float32)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5bd08d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "flat_predictions = np.argmax(flat_predictions)\n",
    "print(flat_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "55c0e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'This bitch needs to be silent'\n",
    "\n",
    "sentence = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "tokenized_sentence = [tokenizer.tokenize(sentence)]\n",
    "\n",
    "MAX_LEN = 128\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_sentence]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24d02c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7897427,  4.3276453]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "\n",
    "model.eval()\n",
    "logits = model(prediction_inputs, token_type_ids=None, attention_mask=prediction_masks)\n",
    "\n",
    "logits['logits'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e97fac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "predictions.append(logits['logits'].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f762c4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-3.7897427,  4.3276453], dtype=float32)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6a4df568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "flat_predictions = np.argmax(flat_predictions)\n",
    "print(flat_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "79cb5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intesity(sentence):\n",
    "    sentence = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    tokenized_sentence = [tokenizer.tokenize(sentence)]\n",
    "\n",
    "    MAX_LEN = 128\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_sentence]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    attention_masks = []\n",
    "\n",
    "    # Create a mask of 1s for each token followed by 0s for padding\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "        \n",
    "    prediction_inputs = torch.tensor(input_ids)\n",
    "    prediction_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    model.eval()\n",
    "    logits = model(prediction_inputs, token_type_ids=None, attention_mask=prediction_masks)\n",
    "    predictions = []\n",
    "    predictions.append(logits['logits'].detach().cpu().numpy())\n",
    "    \n",
    "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "    flat_predictions = np.argmax(flat_predictions)\n",
    "    \n",
    "    if flat_predictions == 1:\n",
    "        return \"Hateful\"\n",
    "    \n",
    "    return \"Not Hateful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "68713de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hateful\n"
     ]
    }
   ],
   "source": [
    "print(predict_intesity(\"She is a gay black bitch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b7429cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"bert-hate-speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9ea8d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-hate-speech\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d354d907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-hate-speech\",\n",
       "  \"architectures\": [\n",
       "    \"BertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"problem_type\": \"single_label_classification\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.34.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77847d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
